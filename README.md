# Розпізнавання емоцій за виразом обличчя

Система розпізнавання емоцій у реальному часі, яка використовує точки обличчя MediaPipe Face Mesh та класифікацію на основі правил для визначення емоцій із потоку вебкамери. Система обчислює геометричні параметри обличчя (відкритість очей, форма рота, положення брів, кривизна усмішки) та класифікує їх в одну з п'яти емоцій: **Happy** (Радість), **Surprised** (Здивування), **Angry** (Злість), **Sad** (Сум) або **Neutral** (Нейтральний).

Система включає індивідуальну калібрацію базової лінії, щоб пороги адаптувалися до пропорцій обличчя конкретної людини, та темпоральне згладжування за допомогою експоненціального ковзного середнього (EMA) для усунення мерехтіння мітки між кадрами.

## Налаштування

### Вимоги

- Python 3.8+
- Вебкамера

### Залежності

Встановіть Python-пакети:

```bash
pip install -r requirements.txt
```

Залежності:

| Пакет | Призначення |
|---|---|
| `opencv-python` | Захоплення з вебкамери, відображення зображення, малювання накладок |
| `mediapipe` | Визначення точок обличчя (468-точкова Face Mesh) |
| `numpy` | Евклідова відстань та операції з масивами |

### Модель Face Landmarker

Система потребує файл моделі MediaPipe Face Landmarker `face_landmarker.task` у кореневій директорії проєкту. Завантажте його з [документації MediaPipe](https://developers.google.com/mediapipe/solutions/vision/face_landmarker#models), якщо він ще відсутній.

### Запуск

```bash
python main.py
```

Після запуску система відкриває вебкамеру, проводить фазу калібрації (~3 секунди), а потім переходить до основного циклу розпізнавання. Натисніть **q** у будь-який момент для виходу.

## Огляд системи

```
main.py                  Точка входу — калібрація, основний цикл, відображення, експорт
landmark_utils.py        Обчислення геометричних параметрів із 468 точок обличчя
emotion_classifier.py    Класифікатор на основі правил (абсолютний + дельта-режими)
calibration.py           Збір кадрів нейтрального обличчя та обчислення індивідуальної базової лінії
smoothing.py             Фільтр експоненціального ковзного середнього для згладжування параметрів
```

### `main.py`

Організовує повний конвеєр обробки:
1. Відкриває вебкамеру та ініціалізує MediaPipe FaceLandmarker у відеорежимі.
2. Запускає фазу калібрації (`run_calibration`), яка збирає 90 кадрів нейтрального обличчя (~3 секунди при 30 fps) та обчислює індивідуальну базову лінію. Якщо користувач натискає `q` під час калібрації або обличчя не виявлено, система переходить у режим абсолютних порогів.
3. Переходить до основного циклу: кожен кадр захоплюється, точки обличчя виділяються, сирі параметри згладжуються через EMA, а згладжені значення передаються класифікатору разом із базовою лінією (якщо доступна).
4. Малює точки обличчя, поточну мітку емоції, режим класифікації (`[CALIBRATED]` або `[ABSOLUTE]`) та значення параметрів у реальному часі на відеопотоці.
5. Записує відлагоджувальний вивід у консоль кожні 30 кадрів.
6. При виході записує покадрові дані у файли CSV та JSON у директорії `output/`.

### `landmark_utils.py`

Обчислює всі геометричні параметри обличчя з 468-точкової моделі MediaPipe Face Mesh. Кожен параметр нормалізується за шириною або висотою обличчя, тому значення не залежать від масштабу. Детальний опис кожного параметра дивіться у розділі [Параметри](#параметри).

### `emotion_classifier.py`

Містить логіку класифікації на основі правил. Працює у двох режимах:
- **Абсолютний режим** (`_classify_absolute`) — використовує фіксовані пороги; працює без калібрації.
- **Дельта-режим** (`_classify_delta`) — обчислює різницю між поточним значенням та відкаліброваною нейтральною базовою лінією, потім застосовує дельта-пороги. Активується автоматично при успішній калібрації.

### `calibration.py`

`BaselineCalibrator` збирає знімки параметрів обличчя протягом 90 кадрів, поки користувач тримає нейтральний вираз. Усереднює кожен параметр по всіх зібраних кадрах для отримання стабільного словника базової лінії.

### `smoothing.py`

`ParameterSmoother` застосовує експоненціальне ковзне середнє (EMA) до кожного скалярного параметра. Формула:

```
smoothed = alpha * new_value + (1 - alpha) * previous_smoothed
```

Стандартне значення `alpha=0.3` означає, що кожен кадр вносить 30% нового значення та зберігає 70% попереднього згладженого значення, забезпечуючи стабільний вивід при збереженні реакції на реальні зміни виразу обличчя.

## Параметри

П'ять скалярних параметрів обчислюються з точок обличчя на кожному кадрі:

### Eye Aspect Ratio (EAR) — Співвідношення сторін ока

Вимірює ступінь відкритості очей.

```
EAR = (||p2 - p6|| + ||p3 - p5||) / (2 * ||p1 - p4||)
```

Де p1-p6 — шість точок навколо кожного ока (зовнішній кут, верхня зовнішня, верхня внутрішня, внутрішній кут, нижня внутрішня, нижня зовнішня). Обчислюється окремо для кожного ока, потім усереднюється. Вищі значення означають ширше відкриті очі; нижчі — примружування або закриті очі.

### Mouth Aspect Ratio (MAR) — Співвідношення сторін рота

Вимірює ступінь відкритості рота.

```
MAR = (v_a + v_b + v_c) / (3 * horizontal)
```

Три вертикальні відстані рота (центр верх-низ, верхня внутрішня ліва до нижньої внутрішньої лівої, верхня внутрішня права до нижньої внутрішньої правої), поділені на горизонтальну відстань між кутами рота. Вищі значення означають більш відкритий рот.

### Smile Coefficient — Коефіцієнт усмішки

Вимірює підняття кутів рота відносно центру рота, нормалізоване за висотою обличчя.

```
smile_coeff = (center_y - corner_avg_y) / face_height
```

Оскільки піксельні y-координати зростають донизу, позитивне значення означає, що кути рота вище за центр (усмішка). Негативне значення означає, що кути опущені (сум). Значення малі (зазвичай від -0.01 до +0.01), оскільки нормалізовані за висотою обличчя.

### Mouth Width — Ширина рота

Горизонтальна відстань між лівим та правим кутами рота, нормалізована за шириною обличчя.

```
mouth_width = ||left_corner - right_corner|| / face_width
```

Збільшується під час усмішки, коли рот розтягується горизонтально. Типові нейтральні значення — приблизно 0.38-0.42.

### Brow Distance — Відстань брів

Середня відстань від брови до верхньої повіки, нормалізована за висотою обличчя.

```
brow_dist = (right_inner + right_mid + left_inner + left_mid) / (4 * face_height)
```

Використовує внутрішні та середні точки брів з кожного боку для надійності. Нижчі значення вказують на насуплені або опущені брови (пов'язано зі злістю або зосередженістю).

## Розпізнавані емоції

Класифікатор перевіряє правила у порядку пріоритету та повертає перший збіг:

### 1. Surprised (Здивування)

Широко відкриті очі **та** широко відкритий рот.

| Режим | Умова |
|---|---|
| Абсолютний | `EAR > 0.30` та `MAR > 0.5` |
| Дельта | `d_ear > +0.04` та `d_mar > +0.35` |

### 2. Happy (Радість)

Кути рота підняті **та** (рот злегка відкритий **або** рот розширений).

| Режим | Умова |
|---|---|
| Абсолютний | `smile > 0.005` та (`MAR >= 0.1` або `mouth_width > 0.43`) |
| Дельта | `d_smile > +0.006` та (`d_mar > -0.01` або `d_mw > +0.015`) |

### 3. Angry (Злість)

Усмішка падає нижче нейтрального рівня **та** (брови насуплені **або** очі звужені з напруженим ротом). Два шляхи визначення, щоб сильний сигнал в одному вимірі не блокувався граничним значенням іншого.

| Режим | Умова |
|---|---|
| Абсолютний | `smile < 0.005` та (`brow_dist < 0.055` або (`EAR < 0.26` та `MAR < 0.15`)) |
| Дельта | `d_smile < -0.006` та (`d_brow < -0.02` або (`d_ear < -0.03` та `d_mar < 0.08`)) |

### 4. Sad (Сум)

Кути рота опущені з нормальними очима та нормальними бровами. Захист за бровами запобігає потраплянню злих облич у категорію "Сум".

| Режим | Умова |
|---|---|
| Абсолютний | `smile < -0.005` та `EAR >= 0.26` та `brow_dist >= 0.055` |
| Дельта | `d_smile < -0.006` та `d_ear >= -0.03` та `d_brow >= -0.02` |

### 5. Neutral (Нейтральний)

Повертається, коли жодне інше правило не спрацювало.

## Калібрація та згладжування

### Індивідуальна калібрація базової лінії

**Проблема:** Фіксовані абсолютні пороги (наприклад, `EAR_LOW = 0.26`) припускають, що у всіх однакові пропорції обличчя у спокої. Людина з природно вузькими очима може постійно отримувати мітку "Angry", оскільки її EAR у стані спокою нижчий за поріг.

**Рішення:** При запуску система збирає 90 кадрів (~3 секунди) нейтрального обличчя користувача та усереднює кожен параметр для побудови персональної базової лінії. Під час класифікації система обчислює дельти (поточне значення мінус базова лінія) та застосовує дельта-пороги. Це означає, що "Happy" визначається як *збільшення вашого коефіцієнта усмішки відносно вашого нейтрального стану*, а не перевищення фіксованого числа.

**Резервний режим:** Якщо калібрація пропущена (натиснуто `q`) або не вдалася (обличчя не виявлено), система переходить у режим абсолютних порогів і продовжує працювати.

### Темпоральне згладжування (EMA)

**Проблема:** Позиції точок обличчя MediaPipe злегка тремтять між кадрами, навіть коли обличчя нерухоме. Це спричиняє коливання параметрів, через що мітка емоції швидко мерехтить.

**Рішення:** Експоненціальне ковзне середнє (EMA) з `alpha = 0.3` згладжує кожен параметр перед класифікацією. Згладжене значення — це зважена суміш нового показника (30%) та попереднього згладженого значення (70%). Це усуває тремтіння, зберігаючи здатність відстежувати реальні зміни виразу обличчя протягом кількох кадрів.

Як сирі, так і згладжені значення експортуються, щоб ефект згладжування можна було перевірити.

## Вивід

### Накладка на вебкамеру

Відеопотік у реальному часі відображає:
- Зелені точки на всіх 468 точках обличчя
- Мітку визначеної емоції та режим класифікації (наприклад, `Emotion: Happy  [CALIBRATED]`) жовтим кольором
- Значення параметрів у реальному часі (EAR, MAR, Smile, Mouth W, Brow D) білим кольором

Під час калібрації замість цього відображається шкала прогресу та текст із інструкцією.

### Консольні логи

Кожні 30 кадрів виводиться відлагоджувальний рядок:

```
[CALIBRATED] [     Happy]  EAR=0.287  MAR=0.152  Smile=0.0081  MouthW=0.441  BrowD=0.0612
```

Він включає режим класифікації, визначену емоцію та всі згладжені значення параметрів.

### Експорт CSV

Зберігається у `output/session_<timestamp>.csv`. Кожен рядок — один кадр:

| Стовпець | Опис |
|---|---|
| `frame` | Номер кадру (починаючи з 1) |
| `timestamp` | Мітка часу Unix у мілісекундах |
| `emotion` | Мітка визначеної емоції |
| `ear_avg_raw` | Сире (незгладжене) співвідношення сторін ока |
| `mar_raw` | Сире співвідношення сторін рота |
| `smile_coeff_raw` | Сирий коефіцієнт усмішки |
| `mouth_width_raw` | Сира ширина рота |
| `brow_dist_raw` | Сира відстань брів |
| `ear_avg_smooth` | Згладжене співвідношення сторін ока |
| `mar_smooth` | Згладжене співвідношення сторін рота |
| `smile_coeff_smooth` | Згладжений коефіцієнт усмішки |
| `mouth_width_smooth` | Згладжена ширина рота |
| `brow_dist_smooth` | Згладжена відстань брів |

### Експорт JSON

Зберігається у `output/session_<timestamp>.json`. Містить метадані та всі покадрові записи:

```json
{
  "session": "20260212_143052",
  "calibration": {
    "enabled": true,
    "baseline": {
      "ear_avg": 0.285,
      "mar": 0.098,
      "mouth_width": 0.401,
      "smile_coeff": 0.00012,
      "brow_dist": 0.0589
    }
  },
  "smoothing": {
    "enabled": true,
    "alpha": 0.3
  },
  "frames": [
    {
      "frame": 1,
      "timestamp": 1739367052000,
      "emotion": "Neutral",
      "ear_avg_raw": 0.2853,
      "mar_raw": 0.0981,
      "smile_coeff_raw": 0.00015,
      "mouth_width_raw": 0.4012,
      "brow_dist_raw": 0.05891,
      "ear_avg_smooth": 0.2853,
      "mar_smooth": 0.0981,
      "smile_coeff_smooth": 0.00015,
      "mouth_width_smooth": 0.4012,
      "brow_dist_smooth": 0.05891
    }
  ]
}
```

Коли калібрація пропущена, `calibration.enabled` дорівнює `false`, а `calibration.baseline` дорівнює `null`.
